{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network():\n",
    "    def __init__(self,\n",
    "                input_states,\n",
    "                num_layers,\n",
    "                nurons_list,\n",
    "                output_states,\n",
    "                session):\n",
    "        \n",
    "        # Check if the number of neurons in each layer is \n",
    "        if len(nurons_list) != num_layers:\n",
    "            raise ValueError(\"nurons_list != num of layers\")\n",
    "        \n",
    "        #Initalize the session\n",
    "        self.session = session\n",
    "        \n",
    "        # Initialize the network\n",
    "        self.input_states = tf.placeholder(dtype=tf.float64, shape=[None, input_states])\n",
    "        self.target_states = tf.placeholder(dtype=tf.float64, shape=[None, output_states])\n",
    "        \n",
    "        # Create a dictonary of weight and states based on the input layers\n",
    "        # Compute the dimentions of the weight bias matrix\n",
    "        self.network_depth = num_layers\n",
    "        \n",
    "        nurons_list.append(output_states)\n",
    "        nurons_list = [input_states] + nurons_list\n",
    "        \n",
    "        self.network_width = nurons_list # list of nurons in each layer including input and output \n",
    "        \n",
    "        self.weights = {}\n",
    "        self.bias = {}\n",
    "        for i in range(0, self.network_depth+1):\n",
    "            self.weights[\"w\"+str(i)] = tf.Variable(np.random.rand(self.network_width[i], self.network_width[i+1]), dtype=tf.float64)\n",
    "            self.bias[\"b\"+str(i)] = tf.Variable(np.random.rand(self.network_width[i+1]), dtype=tf.float64)\n",
    "        \n",
    "        # Initialize the variables \n",
    "        self.session.run(tf.global_variables_initializer())\n",
    "        \n",
    "        # Set the computation graph for the network\n",
    "        self.forward_pass = {}\n",
    "        # First layer\n",
    "        self.forward_pass[\"z1\"] = tf.tensordot(self.input_states, self.weights[\"w0\"], axes=1) + self.bias[\"b0\"]\n",
    "        self.forward_pass[\"y1\"] = tf.nn.relu(self.forward_pass[\"z1\"]) # Make this a user choice \n",
    "        \n",
    "        for i in range(2, self.network_depth+1):\n",
    "            self.forward_pass[\"z\"+str(i)] = tf.tensordot(self.forward_pass[\"y\"+str(i-1)],\n",
    "                                                         self.weights[\"w\"+str(i-1)],\n",
    "                                                         axes=1) + self.bias[\"b\"+str(i-1)]\n",
    "            self.forward_pass[\"y\"+str(i)] = tf.nn.relu(self.forward_pass[\"z\"+str(i)])\n",
    "            \n",
    "        # Final Layer with out activation\n",
    "        self._predict = tf.tensordot(self.forward_pass[\"y\"+str(self.network_depth)],\n",
    "                                    self.weights[\"w\"+str(self.network_depth)],\n",
    "                                    axes=1) + self.bias[\"b\"+str(self.network_depth)]\n",
    "        \n",
    "        # Loss function\n",
    "        self.loss = tf.reduce_mean(tf.square(self._predict - self.target_states))\n",
    "        \n",
    "        # Optimizer \n",
    "        self.optimizer = tf.train.AdamOptimizer()\n",
    "        \n",
    "        # Training\n",
    "        self._train = self.optimizer.minimize(self.loss)\n",
    "        \n",
    "    def predict(self, input_states):\n",
    "        return self.session.run(self._predict, {self.input_states:input_states})\n",
    "    \n",
    "    def train(self, input_states, target_states):\n",
    "        return self.session.run(self._train, \n",
    "                                {self.input_states:input_states,\n",
    "                                 self.target_states:target_states})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1649.91485255,  1584.63693889]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2358904.1307523968"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
